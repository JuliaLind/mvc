## kmom06

PHP metrics var ett bra verktyg som hade många värden man kunde titta på. Jag tyckte att LCOM värdet, cyklomatisk komplexitet per klass och även den högsta cyklomatiska komplexiteten för metod i klassen var särskilt intressanta. Och likaså maintainability index.  

Det var också motiverande att i översikten visuellt se hur cirklarna minskade i diameter och ändrade färg -  en bekräftelse på att man var på rätt väg enligt Scrutinizers mått. Med det sagt så skulle jag inte utgå helt och hållet från att kod som bara har små gröna cirklar är lättare att underhålla - jag skulle säga att jag har mindre koll på min egna kod nu än tidigare. Under tidspress har jag gjort snabblösningar och "flyttat" om kod på ett sätt som inte är helt logiskt, jag har introducerat fler Couplings och tidigare visste jag intuitivt precis var alla delar av koden låg och nu måste jag gå in i varje fil och leta. Detta hade såklart kunnat fixas genom att döpa om klasser, filer och metoder till mer logiska namn, men även det kräver sin tid.  

Jag tror iaf att det kommer att göra stor skillnad för koden i projektet att ha tillgång till detta verktyg, jag kommer att köra rapporten precis hela tiden :)

Scrutinizer var också ett väldigt bra verktyg. Jag hade lite problem med buildfasen i den initiella uppladdningen för att jag hade lite fel inställningar i .scrutinizer.yml fil och även för var clover filen skulle hamna (jag trodde att den skulle läggas i doc/coverage men den skulle tydligen läggas direkt under doc) men fick snabb hjälp med det i chatten. Mitt första betyg var 9.7 och senare fick jag upp det till 10.0.  Jag fick en känsla av att Scrutinizer är mycket snällare än Metrics - jag hade A på alla klasser redan från start och det gav lite motsatta signaler än Metrics representation där samma klass kunde vara representerad som en stor röd cirkel.  Scrutiniser var bättre på att hitta specifika issues och hinta om mer exakt var i koden felet låg - denna detaljerade funktionalitet saknade jag lite i Metrics.

Jag tror att man kan påvisa god kodkvalitet med hjälp av dessa verktyg om man redan från start har använt sig av de och kombinerat med enhetstestning.  Om man "lagar" koden i efterhand  med hjälp av verktygen så är det nog viktigt att inte stirra sig blind på värdena och inte gå för fort fram utan göra det på ett genomtänkt och rätt sätt (motsatsen till vad jag gjorde i veckan med andra ord).  

Full kodtäckning behöver exempelvis inte betyda att testerna är bra, men det tyder iallafall på bättre kvalite än om det inte hade funnits några tester alls. Låg cyklomatisk komplexitet behöver inte betyda att koden är lättare att följa om komplexiteten är uppdelad mellan metoder på ett inte helt logiskt sett (tror tyvärr att detta är mitt fall efter "förbättringarna"). Kod som jag själv tycker är enkel att sätta sig in i är kod där namn på variabler och funktioner är lätta att förstå - beskrivande och gärna enkla ord. Bra kommentarer gör också stor skillnad, jag hann tyvärr inte uppdatera kommentarerna i min kod så mycket i samband med de senaste ändringarna. Det är också viktigt hur koden är strukturerad i namespaces och i mappar, ju större projekt desto viktigare med ordning.  

Efter denna vecka har min kod blivit något enklare att göra ändringar i pga bättre kodtäckning. Det finns också mer utrymme för att bygga på befintliga klasser ioch med att varje klass nu har färre metoder än i början på veckan. Det sistnämnda gäller framförallt controller-klassena. Däremot är inte koden längre uppdelad på ett särskilt logiskt sett, det är svårt att direkt utefter klassnamnen förstå vad som hänger ihop med vad och vad skillnaden är mellan ena klassen och andra eftersom flera av namnen blev snarlika. Och detta tror jag drar ner på min egen kodkvalitet rejält - tyvärr fångas inte denna "röra" upp av varken Scrutinizer eller Metrics.  

Jag tar med mig flera TIL från detta kursmoment som kommer att vara mycket användbara i framtiden:  

- Att Metrics och Scrutinizer finns och vad de olika värdena betyder  

- Hur man mockar returvärden från inbyggda funktioner för testning - det räckte tydligen med att deklarera en funktion med samma namn och samma typ/antal inparametrar i den egna namespace och hårdkoda ett specifikt returvärde som man vill ska returneras. När den inbyggda funktionen kallas på från samma namespace så är det istället denna som kommer att exekveras. Scrutinizer tyckte inte riktigt om denna "fuling" eftersom inparametrarna i den "egendeklarerade" funktionen då aldrig blev använda, men det kommenterade jag bort med 'ignore-unused'. På så sätt kunde jag mocka både returvärden från file_get_contents och från rand_int.  
